{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BQjn_bXqlrJI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def process_frame(image):\n",
        "    # Convert the input image to HLS color space\n",
        "    image_hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "\n",
        "    # Define color range for white mask\n",
        "    lower_threshold = np.uint8([0, 200, 0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(image_hls, lower_threshold, upper_threshold)\n",
        "\n",
        "    # Define color range for yellow mask\n",
        "    lower_threshold = np.uint8([10, 0, 100])\n",
        "    upper_threshold = np.uint8([40, 255, 255])\n",
        "    yellow_mask = cv2.inRange(image_hls, lower_threshold, upper_threshold)\n",
        "\n",
        "    # Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "\n",
        "    # Apply the mask to the input image\n",
        "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    # Convert the masked image to grayscale\n",
        "    masked_image_gray = cv2.cvtColor(masked_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to the grayscale image\n",
        "    masked_image_gray_blur = cv2.GaussianBlur(masked_image_gray, (13, 13), 0)\n",
        "\n",
        "    # Apply Canny edge detection to the blurred image\n",
        "    masked_image_gray_blur_edge_detec = cv2.Canny(masked_image_gray_blur, 50, 150)\n",
        "\n",
        "    # Create a region of interest mask\n",
        "    mask = np.zeros_like(masked_image_gray_blur_edge_detec)\n",
        "    channel_count = image.shape[2]\n",
        "    ignore_mask_color = (255,) * channel_count\n",
        "    rows, cols = image.shape[:2]\n",
        "    bottom_left = [cols * 0.1, rows * 0.95]\n",
        "    top_left = [cols * 0.4, rows * 0.6]\n",
        "    bottom_right = [cols * 0.9, rows * 0.95]\n",
        "    top_right = [cols * 0.6, rows * 0.6]\n",
        "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
        "    mask = cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "\n",
        "    # Apply the region of interest mask to the edge detected image\n",
        "    masked_image = cv2.bitwise_and(masked_image_gray_blur_edge_detec, mask)\n",
        "\n",
        "    # Apply Hough transform to the masked image\n",
        "    hough_lines = cv2.HoughLinesP(masked_image, rho=1, theta=np.pi/180, threshold=20, minLineLength=20, maxLineGap=300)\n",
        "\n",
        "    # Draw Hough lines on a copy of the input image\n",
        "    image_co = np.copy(image)\n",
        "    for line in hough_lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            cv2.line(image_co, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Separate left and right lane lines\n",
        "    left_lines = []\n",
        "    left_weights = []\n",
        "    right_lines = []\n",
        "    right_weights = []\n",
        "\n",
        "    for line in hough_lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            if x1 == x2:\n",
        "                continue\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - (slope * x1)\n",
        "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))  # Calculate the length of the line\n",
        "            if slope < 0:  # If the slope is negative, it's a left line\n",
        "                left_lines.append((slope, intercept))\n",
        "                left_weights.append((length))\n",
        "            else:  # If the slope is positive, it's a right line\n",
        "                right_lines.append((slope, intercept))\n",
        "                right_weights.append((length))\n",
        "\n",
        "    # Calculate the weighted average of the left and right lane lines\n",
        "    left_lane = np.dot(left_weights, left_lines) / np.sum(left_weights) if len(left_weights) > 0 else None\n",
        "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
        "\n",
        "    # Function to convert a line's slope and intercept to pixel points\n",
        "    def pixel_points(y1, y2, line):\n",
        "        if line is None:\n",
        "            return None\n",
        "        slope, intercept = line\n",
        "        x1 = int((y1 - intercept) / slope)\n",
        "        x2 = int((y2 - intercept) / slope)\n",
        "        y1 = int(y1)\n",
        "        y2 = int(y2)\n",
        "\n",
        "        return ((x1, y1), (x2, y2))\n",
        "\n",
        "    # Calculate pixel points for left and right lane lines\n",
        "    y1 = image.shape[0]\n",
        "    y2 = y1 * 0.65\n",
        "    left_line = pixel_points(y1, y2, left_lane)\n",
        "    right_line = pixel_points(y1, y2, right_lane)\n",
        "\n",
        "    # Draw left and right lane lines on a blank image\n",
        "    line_image = np.zeros_like(image)\n",
        "    for line in (left_line, right_line):\n",
        "        if line is not None:\n",
        "            cv2.line(line_image, *line, [0, 255, 0], 5)\n",
        "\n",
        "    # Combine the input image and the line image\n",
        "    draw_lane_lines = cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
        "\n",
        "    # If left and right lane lines are detected, add a green overlay between them\n",
        "    if left_line is not None and right_line is not None:\n",
        "        green_overlay = np.zeros_like(image)\n",
        "        pts = np.array([left_line[0], left_line[1], right_line[1], right_line[0]], dtype=np.int32)\n",
        "        cv2.fillPoly(green_overlay, [pts], (0, 255, 0))\n",
        "        line_image = cv2.addWeighted(line_image, 1, green_overlay, 0.3, 0)\n",
        "\n",
        "    # Combine the input image and the final line image (with green overlay if applicable)\n",
        "    draw_lane_line = cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
        "\n",
        "    return draw_lane_line\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Function to process video frames using the `process_frame` function and save the result\n",
        "def process_video(input_video_path, output_video_path):\n",
        "    # Read the input video\n",
        "    input_video = VideoFileClip(input_video_path)\n",
        "    # Apply the `process_frame` function to each frame of the input video\n",
        "    processed_video = input_video.fl_image(process_frame)\n",
        "    # Write the processed video to the output path without audio\n",
        "    processed_video.write_videofile(output_video_path, audio=False)\n",
        "\n",
        "# Define input and output folder paths\n",
        "input_folder = 'test_videos'\n",
        "output_folder = 'output_videos'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate over all video files in the input folder\n",
        "for file in os.listdir(input_folder):\n",
        "    file_path = os.path.join(input_folder, file)\n",
        "\n",
        "    # Check if the file is a video file\n",
        "    if file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "        input_video_path = file_path\n",
        "\n",
        "        # Replace the input folder path with the output folder path in the file name\n",
        "        output_video_path = os.path.join(output_folder, file)\n",
        "\n",
        "        # Process the video and save the output\n",
        "        process_video(input_video_path, output_video_path)\n"
      ],
      "metadata": {
        "id": "uu1ulxbXqPYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# Function to process images using the `process_frame` function and save the result\n",
        "def process_image(input_image_path, output_image_path):\n",
        "    # Read the input image\n",
        "    input_image = plt.imread(input_image_path)\n",
        "    # Process the image using the `process_frame` function\n",
        "    processed_image = process_frame(input_image)\n",
        "    # Write the processed image to the output path\n",
        "    cv2.imwrite(output_image_path, processed_image)\n",
        "\n",
        "# Define input and output folder paths\n",
        "input_folder = 'input_images'\n",
        "output_folder = 'output_images'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate over all image files in the input folder\n",
        "for file in glob(os.path.join(input_folder, '*')):\n",
        "    # Check if the file is an image file\n",
        "    if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
        "        input_image_path = file\n",
        "        # Replace the input folder path with the output folder path in the file name\n",
        "        output_image_path = os.path.join(output_folder, os.path.basename(file))\n",
        "        # Process the image and save the output\n",
        "        process_image(input_image_path, output_image_path)\n"
      ],
      "metadata": {
        "id": "aSol_yzerUfs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4T-1kQKtTeg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}